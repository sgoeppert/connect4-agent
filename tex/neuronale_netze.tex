\section{Künstliche Neuronale Netze}

Künstliche neuronale Netze (KNNs), meistens auch einfach nur "neuronale Netze" genannt, haben in den letzten Jahren das Forschungsfeld des maschinellen Lernens revolutioniert, obwohl die ersten Ideen dahinter bereits aus den 1940ern und 50ern stammen. 1943 haben Warren McCulloch und Walter Pitts das konzeptionelle Modell der Neuronen vorgestellt\cite{mccullochLogicalCalculusIdeas1943}. Neuronen sind einzelne Einheiten eines Netzwerks, die Eingaben erhalten, diese verarbeiten und eine Ausgabe erzeugen - ähnlich wie es auch in biologischen Gehirnen geschieht.
\par
Mit neuronalen Netzen sollten Probleme gelöst werden, die algorithmisch schwer zu beschreiben sind, wie zum Beispiel die Erkennung von handgeschriebenen Ziffern. Diese Art von Problem, das Erkennen von Mustern, ist für Menschen sehr leicht zu lösen, aber nur schwer für einen Computer lösbar. Neuronale Netze unterscheiden sich von klassischen Computerprogrammen dadurch, dass ein normales Programm (meistens) linear von der ersten bis zur letzten Zeile ausgeführt wird, während ein neuronales Netz Daten parallel verarbeiten und seine interne Struktur anpassen kann.
\par
Diese Anpassbarkeit macht neuronale Netze so mächtig - sie können lernen. Dies geschieht in der Regel durch das Anpassen von \textit{Gewichten}. Jedes Neuron eines Netzwerks ist mit mindestens einem anderen Neuron verbunden. Diese Verbindung hat ein \textbf{Gewicht}, eine Zahl die das Signal vom einen Neuron zum anderen verstärkt oder abschwächt. Wenn das Netzwerk eine korrekte Ausgabe erzeugt, müssen die Gewichte nicht angepasst werden. Ist die Ausgabe dagegen falsch, so passt sich das Netzwerk an und verändert seine Gewichte um diesen \textbf{Fehler} zu reduzieren.

\subsection{Künstliche Neuronen}
Künstliche Neuronen in heutigen neuronalen Netzen basieren auf dem Perzeptron von Frank Rosenblatt. Ein Perzeptron ist eine kleine Rechenmaschine mit einer oder mehreren Eingaben und einer Ausgabe.

\begin{figure}[!hbt]
	\centering
\begin{tikzpicture}
	[x=1.5cm,y=1.5cm,>=stealth,
	neuron/.style={circle,draw,inner sep=2pt, minimum size=10mm}]
	\node at (-1,1)  (input1) {$x_1$};
	\node at (-1,-1) (input2) {$x_2$};
	\node at (2,0) [neuron] (neuron) {};
	\node (output) [right=2cm of neuron] {Output};
	\draw [->] (input1) -- (neuron) node [above, midway] {$w_1$};
	\draw [->] (input2) -- (neuron) node [above, midway] {$w_2$};
	\draw [->] (neuron) -- (output);
\end{tikzpicture}
\caption{Perzeptron mit zwei Eingaben}
\end{figure}


Daten fließen immer von den Inputs $x_1, x_2, ..., x_n$ durch den Neuron zum Output, es sind sogenannte "feed-forward" Neuronen in einem feed-forward Netzwerk. Das Perzeptron nimmt binäre Inputs entgegen und erzeugt ein binäres Signal am Ausgang.
\par
Rosenblatt schlägt eine einfache Regel vor, um den Output zu berechnen. Er assoziiert reellwertige Gewichte $w_1,w_2,...,w_n$ mit jedem Input, die angeben wie wichtig der jeweilige Input für den Output ist. Der Output des Neurons hängt davon ab, ob die gewichtete Summe der Inputs $\sum_{i} w_i x_i$ größer ist als ein Schwellenwert. Ist sie das, so ist der Output 1, ist sie das nicht so ist er 0.
\begin{equation}
\textrm{output} = \begin{cases} 0 & \sum_{i} w_i x_i \le \textrm{Schwelle}\\
1 & \sum_{i} w_i x_i > \textrm{Schwelle}
 \end{cases}
\end{equation}

Die gewichtete Summe lässt sich mathematisch einfach als das Skalarprodukt zweier Vektoren $x$ und $w$ beschreiben $w \bigcdot x \equiv \sum_{i} w_i x_i$, wobei die Vektoren $x = \begin{pmatrix}x_1, x_2, ..., x_n\end{pmatrix}^T$ und $w = \begin{pmatrix}w_1, w_2, ..., w_n\end{pmatrix}^T$ aus den Inputs und Gewichten bestehen. Anstatt eines Schwellenwertes wird in der Regel ein weiterer Input als sogenanntes Bias verwendet. Mit diesem Bias $b \equiv -\textrm{Schwelle}$ kann die Gleichung als 

\begin{equation}
\textrm{output} = \begin{cases} 0 & w \bigcdot x + b \le 0\\
1 & w \bigcdot x + b > 0
\end{cases}
\end{equation}

geschrieben werden. Das Bias bestimmt wie leicht es ist für das Neuron eine 1 auszugeben. Eine Funktion, die $0$ für Werte $z \le 0$ und $1$ für Werte $z > 0$ ausgibt, wird auch Stufenfunktion genannt. Im Neuron bekommt sie die Aufgabe als sogenannte \textbf{Aktivierungsfunktion}. Dies ist eine nicht-lineare Funktion $h$, die auf die gewichtete Summe der Eingabewerte angewandt wird um so die Aktivierung des Neurons zu berechnen.

\begin{equation}
	\textrm{output} = h(x\bigcdot{w}+b)
\end{equation}

Das Perzeptron kann einfache Operationen der Aussagenlogik wie AND, OR und NAND berechnen sowie andere linear separierbare Probleme lösen\footnote{Zwei Mengen sind linear separierbar wenn sie durch eine Hyperebene (im 2-dimensionalen Raum eine Gerade) getrennt werden können, sodass alle Punkte der einen Menge auf der einen, und alle Punkte der anderen Menge auf der anderen Seite der Hyperebene liegen.}, scheitert aber an nicht linear separierbaren Problemen wie XOR.\\

Ein Neuron kann lernen, indem berechnet wird wie stark er in der Vorhersage daneben lag, also wie groß der Fehler war, um dann die Gewichte des Neurons in die richtige Richtung zu verändern. Hat der Perzeptron eine 0 ausgegeben obwohl es eine 1 sein müsste, so müssen alle Gewichte so angepasst werden, dass die Gewichtete Summe plus das Bias größer ist als 0. Hat der Perzeptron umgekehrt eine 1 statt einer 0 ausgegeben, so müssen die Gewichte in die andere Richtung angepasst werden. Da die Inputs nur positiv sind (0 oder 1) müssen die Gewichte erhöht werden, wenn die Summe zu gering war, und reduziert werden wenn die Summe zu groß war. Der Fehler der Ausgabe berechnet sich durch die Differenz vom erwarteten Wert zum tatsächlichen Output $error = erwartet - output$.

Jedes Gewicht des Neurons muss nun abhängig vom Fehler um einen kleinen Wert $\Delta w_j$  in die richtige Richtung angepasst werden. 
\begin{equation}
w_{j}^{neu} = w_j + \Delta w_j, \forall j \in [1 .. n]
\end{equation}
Dieses $\Delta w_j$ berechnet sich durch Multiplikation des Fehlers mit dem Input. War der Input 1, so war das Gewicht am Fehler beteiligt und sollte angepasst werden.
\begin{equation}
\Delta w_j = x_j \cdot error , \forall j \in [1 .. n]
\end{equation}
Da der Fehler der Stufenfunktion entweder -1, 0 oder 1 ist, fallen die Anpassungen der Gewichte ziemlich drastisch aus. Besser ist es, mit jedem Schritt nur kleine Anpassungen durchzuführen, da sonst über die optimalen Gewichte hinausgeschossen wird. Deshalb wird die Änderung des Gewichts mit einem Parameter $\eta = 0.1$ multipliziert der als \textbf{Lernrate} fungiert.
Die neuen Gewichte sind also
\begin{equation}
w_{j}^{neu} = w_j + \eta \cdot x_j \cdot error, \forall j \in [1 .. n].
\end{equation}

Mit dieser einfachen Lernregel kann ein Perzeptron seine Gewichte anpassen und lernen.\\
\par 
Ein besseres Trainingsergebnis wird allerdings erzielt, wenn kleine Änderungen an den Gewichten nur kleine Änderungen im Output bewirken. Die oben vorgestellte Lernregel sorgt dafür, dass der Output bei kleinen Änderungen komplett von 0 auf 1 umschlägt. Dies ist vor allem der verwendeten Aktivierungsfunktion geschuldet. Die Stufenfunktion ist keine schöne glatte Kurve, stattdessen ist sie konstant 0 für alle Werte bis 0 und springt dann auf 1 für alle positiven Werte. Abhilfe schafft eine andere Aktivierungsfunktion, die sogenannte logistische Funktion oder auch Sigmoid Funktion

\begin{equation}
	\sigma(z) \equiv \frac{1}{1 + e^{-z}}.
\end{equation}

Sigmoid Funktionen haben für große - positive wie negative - Werte ein sehr ähnliches Verhalten zur Stufenfunktion. Für große positive Werte von $z$ wird $e^{-z} \approx 0$ und somit $\sigma(z) \approx 1$ und für stark negative Werte gilt $e^{-z} \rightarrow \infty$ und dadurch $\sigma(z) \approx 0$. Im Bereich nahe der Null ist die Sigmoid Funktion allerdings stetig, streng monoton steigend und kleine Änderungen in $x$ bewirken kleine Änderungen in $y$.

\subsection{Architektur von neuronalen Netzen}
Neuronale Netze bestehen aus mehr als nur einem einzigen Neuron und diese Neuronen sind miteinander verbunden. 